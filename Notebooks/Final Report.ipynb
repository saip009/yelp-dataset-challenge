{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting neighborhoods where new restaurants can open based on categories and price rating\n",
    "This notebook puts our learnings in all other notebooks together. Here we build the final models for predicting the following:\n",
    "- Checkings for a restaurant\n",
    "- If the restaurant will remain open in a neighborhood\n",
    "- Rating of the restaurant\n",
    "\n",
    "All models take the same inputs:\n",
    "- Neighborhood\n",
    "- Categories\n",
    "- Price rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "The restaurants are loaded from `yelp_academic_dataset_business.json`, while the checkins are loaded from `yelp_academic_dataset_checkin.json`.\n",
    "\n",
    "Businesses with at least one of the following categories are considered restaurants:\n",
    "- Restaurant\n",
    "- Food\n",
    "- Bar\n",
    "\n",
    "For each restaurant we only care about the following attributes:\n",
    "- Neighborhood\n",
    "- Price Rating\n",
    "- Select few categories (see full list below)\n",
    "- If the restaurant is open\n",
    "- Restaurant star rating\n",
    "\n",
    "Only th following categories are selected for each restaurant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_categories = {'coffee & tea', 'specialty food', 'sandwiches', 'breakfast & brunch', 'chinese', 'cafes',\n",
    "                     'canadian (new)', 'bakeries', 'fast food', 'pizza', 'desserts', 'italian', 'japanese', 'burgers', 'pubs',\n",
    "                     'american (traditional)', 'sushi bars', 'indian', 'juice bars & smoothies', 'asian fusion', 'korean',\n",
    "                     'mexican', 'middle eastern', 'thai', 'mediterranean', 'salad', 'chicken wings',\n",
    "                     'ice cream & frozen yogurt', 'seafood', 'beer', 'wine & spirits', 'vegetarian', 'comfort food', 'vegan',\n",
    "                     'greek', 'barbeque', 'vietnamese', 'diners', 'caribbean', 'french', 'american (new)', 'halal',\n",
    "                     'ethnic food', 'gluten-free', 'delis', 'tea rooms', 'gastropubs', 'tapas/small plates', 'soup',\n",
    "                     'steakhouses', 'bubble tea', 'dim sum', 'noodles', 'donuts', 'chicken shop', 'portuguese',\n",
    "                     'chocolatiers & shops', 'ramen', 'tapas bars', 'latin american', 'bagels', 'pakistani', 'fish & chips',\n",
    "                     'taiwanese', 'modern european', 'tex-mex', 'british', 'creperies', 'southern', 'filipino', 'african',\n",
    "                     'hot dogs', 'irish', 'poke', 'ethiopian', 'afghan', 'turkish', 'falafel', 'hot pot', 'spanish',\n",
    "                     'local flavor', 'himalayan/nepalese', 'hawaiian', 'lebanese', 'persian/iranian', 'polish', 'waffles',\n",
    "                     'soul food', 'malaysian', 'sri lankan', 'live/raw food'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def Neighborhood(name, index):\n",
    "    return SimpleNamespace(name=name, index=index)\n",
    "\n",
    "def Category(category, index):\n",
    "    return SimpleNamespace(\n",
    "        category = category,\n",
    "        index = index\n",
    "    )\n",
    "\n",
    "class CategoryBuilder(object):\n",
    "    def __init__(self, chosen_categories):\n",
    "        self.cat_to_ind = {cat: i for i, cat in enumerate(chosen_categories)}\n",
    "    \n",
    "    def build(self, category):\n",
    "        category = category.strip().lower()\n",
    "        if (category in self.cat_to_ind):\n",
    "            return Category(category, self.cat_to_ind[category])\n",
    "        return None\n",
    "\n",
    "def Restaurant(business, categoryBuilder):\n",
    "    return SimpleNamespace(\n",
    "        business_id = business['business_id'],\n",
    "        neighborhood = Neighborhood(business['neighborhood'], None),\n",
    "        city = business['city'],\n",
    "        location = [business['latitude'], business['longitude']],\n",
    "        stars = business['stars'],\n",
    "        categories = list(filter(\n",
    "            lambda c: c is not None,\n",
    "            [categoryBuilder.build(category) for category in business['categories'].split(',')]\n",
    "        )),\n",
    "        is_open = bool(business.get('is_open', 0)),\n",
    "        price_rating = int(business['attributes']['RestaurantsPriceRange2'])\n",
    "    )\n",
    "    \n",
    "\n",
    "def getRestaurantsFromFile(sparkContext, restaurant_file, checkins_file, chosen_categories):\n",
    "    restaurant_categories = {'restaurants', 'food', 'bars'}\n",
    "    categoryBuilder = CategoryBuilder(chosen_categories)\n",
    "    restaurants = sparkContext.textFile(restaurant_file) \\\n",
    "        .map(lambda row: json.loads(row)) \\\n",
    "        .filter(lambda business: business['categories'] is not None and business['attributes'] is not None) \\\n",
    "        .filter(lambda business: restaurant_categories & {x.strip().lower() for x in business['categories'].split(',')}) \\\n",
    "        .filter(lambda business: 'RestaurantsPriceRange2' in business['attributes']) \\\n",
    "        .filter(lambda business: business['latitude'] is not None and business['longitude'] is not None) \\\n",
    "        .map(lambda restaurant: Restaurant(restaurant, categoryBuilder)) \\\n",
    "        .keyBy(lambda restaurant: restaurant.business_id)\n",
    "    checkins = sc.textFile(checkins_file) \\\n",
    "        .map(lambda row: json.loads(row)) \\\n",
    "        .map(lambda checkin: (checkin['business_id'], sum(checkin['time'].values())))\n",
    "    def update_restaurant(restaurant, checkins):\n",
    "        restaurant.checkins = checkins\n",
    "        return restaurant\n",
    "    return checkins.join(restaurants) \\\n",
    "        .map(lambda tup: update_restaurant(tup[1][1], tup[1][0])) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = getRestaurantsFromFile(\n",
    "    sc,\n",
    "    '../data/raw/yelp_academic_dataset_business.json',\n",
    "    '../data/raw/yelp_academic_dataset_checkin.json',\n",
    "    chosen_categories\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on the top 4 cities:\n",
    "- Toronto\n",
    "- Pheonix\n",
    "- Las Vagas\n",
    "- Montreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8888\n"
     ]
    }
   ],
   "source": [
    "toronto = [r for r in restaurants if r.city == 'Toronto']\n",
    "print(len(toronto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7872\n"
     ]
    }
   ],
   "source": [
    "vegas = [r for r in restaurants if r.city == 'Las Vegas']\n",
    "print(len(vegas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4666\n"
     ]
    }
   ],
   "source": [
    "phoenix = [r for r in restaurants if r.city == 'Phoenix']\n",
    "print(len(phoenix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3741\n"
     ]
    }
   ],
   "source": [
    "montreal = [r for r in restaurants if r.city == 'MontrÃ©al']\n",
    "print(len(montreal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering into neighborhoods\n",
    "A lot of restaurants don't have any neighborhood assigned. We employ kmeans with a custom distance function to assign neighborhoods to the restaurants per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "import numpy as np\n",
    "\n",
    "def custom_dist(vec1, vec2):\n",
    "    if vec1[2] >= 0 and vec1[2] == vec2[2]:\n",
    "        return 0\n",
    "    return np.linalg.norm(vec1[:2] - vec2[:2])\n",
    "\n",
    "def cluster_restaurants(restaurants, num_clusters):\n",
    "    neighborhood_inds, ind = {}, 0\n",
    "    for r in restaurants:\n",
    "        if r.neighborhood.name not in neighborhood_inds:\n",
    "            r.neighborhood.index = ind\n",
    "            neighborhood_inds[r.neighborhood.name] = ind\n",
    "            ind += 1\n",
    "        else:\n",
    "            r.neighborhood.index = neighborhood_inds[r.neighborhood.name]\n",
    "    \n",
    "    locations = np.array([r.location + [r.neighborhood.index if r.neighborhood.name else -1] for r in restaurants])\n",
    "    clusterer = KMeansClusterer(num_clusters, custom_dist, repeats=2, avoid_empty_clusters=True)\n",
    "    _ = clusterer.cluster(locations, assign_clusters=True)\n",
    "    for r in restaurants:\n",
    "        loc = np.array(r.location + [r.neighborhood.index if r.neighborhood.name else -1])\n",
    "        r.neighborhood.index = clusterer.classify(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_restaurants(toronto, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_restaurants(vegas, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_restaurants(phoenix, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_restaurants(montreal, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def saveToFile(obj, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "def readFromFile(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToFile(toronto, '../data/raw/clustered_restaurants_toronto.pickle')\n",
    "saveToFile(vegas, '../data/raw/clustered_restaurants_vegas.pickle')\n",
    "saveToFile(phoenix, '../data/raw/clustered_restaurants_phoenix.pickle')\n",
    "saveToFile(montreal, '../data/raw/clustered_restaurants_montreal.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto = readFromFile('../data/raw/clustered_restaurants_toronto.pickle')\n",
    "vegas = readFromFile('../data/raw/clustered_restaurants_vegas.pickle')\n",
    "phoenix = readFromFile('../data/raw/clustered_restaurants_phoenix.pickle')\n",
    "montreal = readFromFile('../data/raw/clustered_restaurants_montreal.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from scipy.stats import expon\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "class Classifiers(object):\n",
    "    def __init__(self, restaurants):\n",
    "        self.data = restaurants\n",
    "        self.models = SimpleNamespace(\n",
    "            checkins=BernoulliNB(),\n",
    "            is_open=BernoulliNB(),\n",
    "            stars=MultinomialNB()\n",
    "        )\n",
    "        self.fit()\n",
    "    \n",
    "    def fit(self, test_size=0.2, scoring=accuracy_score):\n",
    "        train_X, test_X = train_test_split(self._get_traing_X(), test_size=test_size, random_state=0)\n",
    "        c_train_Y, c_test_Y = train_test_split(self._get_checkins_Y(), test_size=test_size, random_state=0)\n",
    "        o_train_Y, o_test_Y = train_test_split(self._get_is_open_Y(), test_size=test_size, random_state=0)\n",
    "        s_train_Y, s_test_Y = train_test_split(self._get_stars_Y(), test_size=test_size, random_state=0)\n",
    "        self.models.checkins.fit(train_X, c_train_Y)\n",
    "        self.models.is_open.fit(train_X, o_train_Y)\n",
    "        self.models.stars.fit(train_X, s_train_Y)\n",
    "        p1 = self.models.checkins.predict(test_X)\n",
    "        p2 = self.models.is_open.predict(test_X)\n",
    "        p3 = self.models.stars.predict(test_X)\n",
    "        s1 = scoring(c_test_Y, p1)\n",
    "        s2 = scoring(o_test_Y, p2)\n",
    "        s3 = scoring(s_test_Y, p3)\n",
    "        k1 = stats.ks_2samp(p1, c_test_Y)\n",
    "        k2 = stats.ks_2samp(p2, o_test_Y)\n",
    "        k3 = stats.ks_2samp(p3, s_test_Y)\n",
    "        return SimpleNamespace(\n",
    "            checkins=SimpleNamespace(score=s1, ks_test=k1),\n",
    "            is_open=SimpleNamespace(score=s2, ks_test=k2),\n",
    "            stars=SimpleNamespace(score=s3, ks_test=k3)\n",
    "        )\n",
    "\n",
    "    def predict(self, restaurants):\n",
    "        feature_vecs_X = []\n",
    "        for r in restaurants:\n",
    "            n_feature_vec = np.zeros(self.num_neighborhoods)\n",
    "            n_feature_vec[r.neighborhood.index] = 1\n",
    "            c_feature_vec = np.zeros(self.num_categories)\n",
    "            for c in r.categories:\n",
    "                c_feature_vec[c.index] = 1\n",
    "            p_feature_vec = np.zeros(4)\n",
    "            p_feature_vec[r.price_rating - 1] = 1\n",
    "            feature_vecs_X.append(np.hstack([n_feature_vec, c_feature_vec, p_feature_vec]))\n",
    "        X = np.vstack(feature_vecs_X)\n",
    "        return SimpleNamespace(\n",
    "            checkins=self.models.checkins.predict(X),\n",
    "            is_open=self.models.is_open.predict(X),\n",
    "            stars=self.models.stars.predict(X),\n",
    "        )\n",
    "    \n",
    "    def _get_traing_X(self):\n",
    "        feature_vecs_X = []\n",
    "        self.num_neighborhoods = max(r.neighborhood.index for r in self.data) + 1\n",
    "        self.num_categories = max(cat.index for r in self.data for cat in r.categories) + 1\n",
    "        for r in self.data:\n",
    "            n_feature_vec = np.zeros(self.num_neighborhoods)\n",
    "            n_feature_vec[r.neighborhood.index] = 1\n",
    "            c_feature_vec = np.zeros(self.num_categories)\n",
    "            for c in r.categories:\n",
    "                c_feature_vec[c.index] = 1\n",
    "            #p_feature_vec = np.zeros(4)\n",
    "            #p_feature_vec[r.price_rating - 1] = 1\n",
    "            feature_vecs_X.append(np.hstack([n_feature_vec, c_feature_vec]))\n",
    "        return np.vstack(feature_vecs_X)\n",
    "    \n",
    "    def _get_checkins_Y(self):\n",
    "        feature_vec_Y = [r.checkins for r in self.data]\n",
    "        checkin_bins = self._get_checkin_bins(feature_vec_Y, 5)\n",
    "        return np.digitize(feature_vec_Y, checkin_bins)\n",
    "    \n",
    "    def _get_is_open_Y(self):\n",
    "        return np.array([r.is_open for r in self.data], dtype=np.float)\n",
    "    \n",
    "    def _get_stars_Y(self):\n",
    "        return np.array([r.stars * 2 for r in self.data])\n",
    "    \n",
    "    def _get_checkin_bins(self, checkin_data, num_bins):\n",
    "        _, scale = expon.fit(checkin_data)\n",
    "        # scale is equal to 1/lambda according to http://reliawiki.org/index.php/The_Exponential_Distribution\n",
    "        ret = []\n",
    "        for i in range(num_bins):\n",
    "            p = i / num_bins\n",
    "            ret.append(-math.log(1 - p) * scale)\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(checkins=namespace(ks_test=Ks_2sampResult(statistic=0.2890888638920135, pvalue=1.7059259126120749e-65), score=0.3858267716535433), is_open=namespace(ks_test=Ks_2sampResult(statistic=0.22553430821147358, pvalue=4.9797491213735405e-40), score=0.6856017997750281), stars=namespace(ks_test=Ks_2sampResult(statistic=0.18616422947131606, pvalue=2.0756447582630234e-27), score=0.29190101237345334))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = SimpleNamespace()\n",
    "classifiers.toronto = Classifiers(toronto)\n",
    "classifiers.toronto.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(checkins=namespace(ks_test=Ks_2sampResult(statistic=0.28190476190476194, pvalue=2.8914067617774917e-55), score=0.5041269841269841), is_open=namespace(ks_test=Ks_2sampResult(statistic=0.19873015873015873, pvalue=1.1160954127723686e-27), score=0.6882539682539682), stars=namespace(ks_test=Ks_2sampResult(statistic=0.10793650793650794, pvalue=1.8261476296280326e-08), score=0.2723809523809524))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.vegas = Classifiers(vegas)\n",
    "classifiers.vegas.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(checkins=namespace(ks_test=Ks_2sampResult(statistic=0.3190578158458244, pvalue=3.382371304873677e-42), score=0.4464668094218415), is_open=namespace(ks_test=Ks_2sampResult(statistic=0.22162740899357602, pvalue=1.3983921654055535e-20), score=0.6905781584582441), stars=namespace(ks_test=Ks_2sampResult(statistic=0.10385438972162742, pvalue=7.502485517710985e-05), score=0.2740899357601713))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.phoenix = Classifiers(phoenix)\n",
    "classifiers.phoenix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(checkins=namespace(ks_test=Ks_2sampResult(statistic=0.2990654205607477, pvalue=6.733267702960478e-30), score=0.3658210947930574), is_open=namespace(ks_test=Ks_2sampResult(statistic=0.22296395193591453, pvalue=8.305252117053393e-17), score=0.7476635514018691), stars=namespace(ks_test=Ks_2sampResult(statistic=0.2069425901201602, pvalue=1.5453323186098562e-14), score=0.3164218958611482))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.montreal = Classifiers(montreal)\n",
    "classifiers.montreal.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2901\n"
     ]
    }
   ],
   "source": [
    "print(len([r for r in restaurants if r.city == 'MontrÃ©al' and r.is_open]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
